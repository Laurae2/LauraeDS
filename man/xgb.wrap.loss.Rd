% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/xgb.wrap.loss.R
\name{xgb.wrap.loss}
\alias{xgb.wrap.loss}
\title{xgboost loss function wrapper}
\usage{
xgb.wrap.loss(f)
}
\arguments{
\item{f}{Type: function. The function to wrap from xgboost. Requires the following order of arguments for the function to work: \code{preds, labels}, and returns a vector of the same length of both the inputs.}
}
\value{
The wrapping function.
}
\description{
The wrapper works only if both the wrapper and the original loss metric are existing. Requires \code{Matrix} and \code{xgboost} packages.
}
\examples{
# Note: this example unexpectedly fails when using pkgdown.

library(xgboost)
library(Matrix)
data(agaricus.train, package = "xgboost")
data(agaricus.test, package = "xgboost")

dtrain <- xgboost::xgb.DMatrix(agaricus.train$data, label = agaricus.train$label)
dtest <- xgboost::xgb.DMatrix(agaricus.test$data, label = agaricus.test$label)
watchlist <- list(train = dtrain, eval = dtest)

cross_entropy <- function(preds, labels) {
  preds <- 1 / (1 + exp(-preds))
  grad <- preds - labels
  hess <- preds * (1 - preds)
  return(list(grad = grad, hess = hess))
}
cross_entropy_wrap <- xgb.wrap.loss(f = cross_entropy)

param <- list(max_depth = 2, eta = 1, silent = 1, nthread = 1, 
              objective = cross_entropy_wrap, eval_metric = "auc")
bst <- xgboost::xgb.train(param, dtrain, nrounds = 2, watchlist)

# Note: this example unexpectedly fails when using pkgdown.

}
